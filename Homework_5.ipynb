{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3871b6b-964c-4332-a6fa-aa4ba061ebdf",
   "metadata": {},
   "source": [
    "# Chem 277B - Fall 2024 - Homework 5\n",
    "## ANN - Artificial Neural Networks\n",
    "*Submit this notebook to bCourses to receive a credit for this assignment.*\n",
    "<br>\n",
    "due: **Oct 29th 2024** \n",
    "<br>\n",
    "**Please upload both, the .ipynb file and the corresponding .pdf**<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda39810-091f-482b-a7fb-906c6da69c7f",
   "metadata": {},
   "source": [
    "## 60 Points Total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad98376-0aa9-4d9a-b182-c46a251e90d6",
   "metadata": {},
   "source": [
    "The goal of this homework assignment is to understand how the complexity of the dataset and the design of the ANN (number of neurons and number of layers) with different parameters i.e. like learning rate and activation functions influence the performance of the ANN.<br>\n",
    "**Important: Only use numpy for creating the ANN, pandas for data frames if neccessary and matplotlib/ seaborn for plotting, but no further external python libraries.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2302b60a-2aa0-43a7-bd68-2650720d3a5e",
   "metadata": {},
   "source": [
    "**1) Create an artificial dataset, one for regression and one for classification each** <br>\n",
    "Start with a data set similar to the molecule data set we have been using earlier with a moderate number of features (say five) and about 1000 data points.<br> \n",
    "Normalize the features between 0 and 1 for better convergence and split the dataset into **training and testing set**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c222ec-a21f-44d9-a5a5-5f9b2b34cdc3",
   "metadata": {},
   "source": [
    "**2) Network Design**<br>\n",
    "Use at least two hidden layers and experiment with different layer sizes. Use different activation functions, such like *Sigmoid*, *ReLU* or any other activation function of your choice.<br>\n",
    "Implement dropout between the hidden layers (e.g., randomly drop 20-30% neurons).<br>\n",
    "Add an output layer according to the optimization problem (regression vs classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b6dbb7-6df6-4484-8459-e7c9279e7e0b",
   "metadata": {},
   "source": [
    "**3) Training and Optimization**<br>\n",
    "For regression, use Mean Squared Error (MSE) as the loss function. For classification, use cross entropy as loss function (you can use the codes provided in the lecture). Implement backpropagation manually for weight updates and use gradient descent for optimization. Now, train the network over multiple epochs and track the loss and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dddee3b-f36b-4543-9c27-1c7dc93a3b80",
   "metadata": {},
   "source": [
    "**4) Evaluation**<br>\n",
    "Monitor the loss and the accuracy for the different epochs. For classification, generate a confusion chart and plot a histogramm of the different probabilities (see the lecture) at the end of the training process.<br>\n",
    "Evaluate the performance of the ANN with the test set in the same way.<br>\n",
    "<br>\n",
    "Now, experiment with different<br>\n",
    "- training to test set ratios<br>\n",
    "- different numbers of features in the data (say, $N_{feature} = 3, 5, 20, 50$)\n",
    "- features that correlate\n",
    "- different numbers of data points (say, $N_{sample} = 200, 2\\,000, 5\\,000, 10\\,000$)\n",
    "\n",
    "How does the accuracy change?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6057e2-0c5b-4e79-9cae-b0afc98086f0",
   "metadata": {},
   "source": [
    "**5) Submission Requirements**<br>\n",
    "Include a short report (1-2 pages) explaining:<br>\n",
    "- your architecture choices (layers, neurons, activation functions, etc.)<br>\n",
    "- how dropout was implemented.<br>\n",
    "- training performance (loss and accuracy plots).<br>\n",
    "- results and key insights.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a5664d",
   "metadata": {},
   "source": [
    "## Create artificial dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "133a942c-ae5e-437c-9c14-6ac41887b589",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "from sklearn.preprocessing import MinMaxScaler  #to normalize data\n",
    "\n",
    "def create_dataset(num_data_points, num_features):\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for num in range(num_features):\n",
    "        curr_column = np.random.randint(0, 100, size = num_data_points)\n",
    "        normalized_curr_col = MinMaxScaler().fit_transform(curr_column.reshape(-1,1)).flatten()\n",
    "        df[f\"feature {num+1}\"] = normalized_curr_col.flatten()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e654f519",
   "metadata": {},
   "source": [
    "## make classification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "659ef627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it a classification dataframe\n",
    "\n",
    "def make_class_df(df):\n",
    "    copy_df = df.copy()\n",
    "\n",
    "    columns = df.shape[1]\n",
    "\n",
    "    columns_list = np.arange(1, columns+1)\n",
    "\n",
    "    random_col = np.random.choice(columns_list, 2, replace = False)\n",
    "\n",
    "    toxic = (df[f\"feature {random_col[0]}\"] + df[f\"feature {random_col[1]}\"] >0.7).astype(int)\n",
    "\n",
    "    copy_df['toxic'] = toxic\n",
    "\n",
    "    return copy_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614aa77d",
   "metadata": {},
   "source": [
    "## make Train test split function for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7241da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def tt_split_regression(df, test_percent):\n",
    "\n",
    "    #make last feature Y\n",
    "\n",
    "    Y = df.iloc[:,-1]\n",
    "    display(Y)\n",
    "\n",
    "    X = df.iloc[:,:-1]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = test_percent )\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989c98a",
   "metadata": {},
   "source": [
    "## Train test split function for classification df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ccaa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_split_regression(df, test_percent):\n",
    "\n",
    "    #make last feature Y\n",
    "\n",
    "    Y = df.iloc[:,-1]\n",
    "    display(Y)\n",
    "\n",
    "    X = df.iloc[:,:-1]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = test_percent )\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a2921",
   "metadata": {},
   "source": [
    "## Create regression and classification dataframes and do train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90539cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature 1</th>\n",
       "      <th>feature 2</th>\n",
       "      <th>feature 3</th>\n",
       "      <th>feature 4</th>\n",
       "      <th>feature 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.505051</td>\n",
       "      <td>0.464646</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.252525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.626263</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.717172</td>\n",
       "      <td>0.717172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.424242</td>\n",
       "      <td>0.212121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.292929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.343434</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.929293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.151515</td>\n",
       "      <td>0.919192</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.191919</td>\n",
       "      <td>0.949495</td>\n",
       "      <td>0.474747</td>\n",
       "      <td>0.676768</td>\n",
       "      <td>0.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.494949</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.535354</td>\n",
       "      <td>0.989899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature 1  feature 2  feature 3  feature 4  feature 5\n",
       "0     0.919192   0.505051   0.464646   0.757576   0.252525\n",
       "1     0.626263   0.030303   0.363636   0.717172   0.717172\n",
       "2     0.727273   0.161616   0.969697   0.424242   0.212121\n",
       "3     0.303030   0.727273   0.676768   0.272727   0.292929\n",
       "4     0.303030   0.111111   0.343434   0.969697   0.909091\n",
       "..         ...        ...        ...        ...        ...\n",
       "995   0.525253   0.383838   0.060606   0.606061   0.929293\n",
       "996   0.151515   0.919192   0.222222   0.676768   0.454545\n",
       "997   0.191919   0.949495   0.474747   0.676768   0.484848\n",
       "998   0.656566   0.333333   0.494949   0.848485   0.909091\n",
       "999   0.303030   0.525253   0.606061   0.535354   0.989899\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      0.252525\n",
       "1      0.717172\n",
       "2      0.212121\n",
       "3      0.292929\n",
       "4      0.909091\n",
       "         ...   \n",
       "995    0.929293\n",
       "996    0.454545\n",
       "997    0.484848\n",
       "998    0.909091\n",
       "999    0.989899\n",
       "Name: feature 5, Length: 1000, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " ## create regression dataframe\n",
    "rg_df_1 = create_dataset(1000, 5)\n",
    "\n",
    "#create classificaiton dataframe\n",
    "cl_df_1 = make_class_df(rg_df_1)\n",
    "\n",
    "#train test split regression dataframe\n",
    "x_train_reg, x_test_reg, y_train_reg, y_test_reg = tt_split_regression(rg_df_1, 0.3)\n",
    "\n",
    "#train test split classification dataframe\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msse-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
